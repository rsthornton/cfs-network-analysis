{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interstate Commerce Network Analysis\n",
    "\n",
    "**Research Questions:**\n",
    "1. Which states are most influential in our network of interstate flows?\n",
    "2. What are the most significant flows between those states?\n",
    "\n",
    "**Data Source:** U.S. Census Bureau CFS 2017 Public Use File\n",
    "\n",
    "**Note:** This notebook downloads official Census data and uses validated analysis scripts to reproduce research findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Download CFS Data from Census Bureau\n",
    "\n",
    "Download the official CFS 2017 Public Use File directly from the U.S. Census Bureau (~140MB, takes 2-3 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download CFS 2017 data from Census Bureau\nimport os\nimport urllib.request\nimport zipfile\n\n# Census Bureau official data URL\ndata_url = \"https://www2.census.gov/programs-surveys/cfs/datasets/2017/CFS%202017%20PUF%20CSV.zip\"\n\n# Download if not already present\nif not os.path.exists('cfs_2017_puf.csv'):\n    print(\"Downloading CFS 2017 data from Census Bureau...\")\n    urllib.request.urlretrieve(data_url, 'cfs_data.zip')\n    \n    print(\"Extracting data...\")\n    with zipfile.ZipFile('cfs_data.zip', 'r') as zip_ref:\n        zip_ref.extractall('.')\n    \n    # Rename the extracted file to match what our scripts expect\n    if os.path.exists('CFS 2017 PUF CSV.csv'):\n        os.rename('CFS 2017 PUF CSV.csv', 'cfs_2017_puf.csv')\n        print(\"Renamed file to cfs_2017_puf.csv\")\n    \n    # Clean up zip file\n    os.remove('cfs_data.zip')\n    print(\"Data downloaded successfully!\")\nelse:\n    print(\"CFS data already present.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Analysis Scripts from GitHub\n",
    "\n",
    "Download our validated analysis scripts from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download analysis scripts from GitHub\n",
    "import urllib.request\n",
    "\n",
    "# GitHub raw file URLs\n",
    "base_url = \"https://raw.githubusercontent.com/rsthornton/cfs-network-analysis/main/analysis/\"\n",
    "\n",
    "scripts = [\n",
    "    \"centrality_analysis.py\",\n",
    "    \"flow_extraction.py\"\n",
    "]\n",
    "\n",
    "for script in scripts:\n",
    "    if not os.path.exists(script):\n",
    "        print(f\"Downloading {script}...\")\n",
    "        urllib.request.urlretrieve(base_url + script, script)\n",
    "        print(f\"  ✓ {script} downloaded\")\n",
    "    else:\n",
    "        print(f\"  ✓ {script} already present\")\n",
    "\n",
    "print(\"\\nAnalysis scripts ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Required Libraries\n",
    "\n",
    "Install the necessary Python packages for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas networkx matplotlib seaborn -q\n",
    "\n",
    "print(\"Required libraries installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Three-Level Centrality Analysis\n",
    "\n",
    "Identify the most influential states using our three-level framework:\n",
    "- **MACRO**: Regional bridging power (betweenness centrality)\n",
    "- **MESO**: Influence networks (eigenvector centrality)\n",
    "- **MICRO**: Distribution power (weighted out-degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run centrality analysis\n!python centrality_analysis.py --data cfs_2017_puf.csv --top-n 10\n\nprint(\"\\nCentrality analysis complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load and Display Centrality Results\n",
    "\n",
    "Load the results and create a simple summary table showing the most influential states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport json\nimport matplotlib.pyplot as plt\n\n# Check if results directory exists\nif not os.path.exists('results'):\n    print(\"ERROR: Results directory not found. Please run Step 4 first.\")\nelse:\n    # Load centrality results\n    results_files = os.listdir('results')\n    json_files = [f for f in results_files if f.startswith('centrality_analysis') and f.endswith('.json')]\n    \n    if not json_files:\n        print(\"ERROR: No centrality analysis results found. Please run Step 4 first.\")\n    else:\n        json_file = json_files[0]\n        \n        with open(f'results/{json_file}', 'r') as f:\n            results = json.load(f)\n        \n        # Create summary table of top 5 states at each level\n        print(\"=\" * 60)\n        print(\"MOST INFLUENTIAL STATES BY LEVEL (Top 5)\")\n        print(\"=\" * 60)\n        \n        levels = [\n            ('MACRO - Regional Bridging', 'macro_level'),\n            ('MESO - Influence Networks', 'meso_level'),\n            ('MICRO - Distribution Power', 'micro_level')\n        ]\n        \n        for level_name, level_key in levels:\n            print(f\"\\n{level_name}:\")\n            leaders = results['three_level_analysis'][level_key]['leaders'][:5]\n            for i, state_data in enumerate(leaders, 1):\n                # state_data is a list: [state_id, state_code, score]\n                state_code = state_data[1]\n                score = state_data[2]\n                print(f\"  {i}. {state_code}: {score:.3f}\")\n        \n        # Show multi-level leaders\n        print(\"\\n\" + \"=\" * 60)\n        print(\"MULTI-LEVEL LEADERS (States appearing in multiple rankings)\")\n        print(\"=\" * 60)\n        for state in results['three_level_analysis']['multi_level_leaders'][:5]:\n            print(f\"  {state['state_name']}: {state['level_count']} levels - Score: {state['total_score']:.2f}\")\n        \n        # Create visualization showing key finding: TX, CA, NY as top 3 influential states\n        print(\"\\n\" + \"=\" * 60)\n        print(\"KEY FINDING: Most Influential States in Network\")\n        print(\"=\" * 60)\n        \n        fig, ax = plt.subplots(figsize=(10, 6))\n        \n        # Show MESO level (Influence Networks) - the key research finding\n        meso_leaders = results['three_level_analysis']['meso_level']['leaders'][:10]\n        states = [leader[1] for leader in meso_leaders]\n        scores = [leader[2] for leader in meso_leaders]\n        \n        # Highlight top 3 (TX, CA, NY) in different colors\n        colors = ['#d73027' if i < 3 else 'steelblue' for i in range(len(states))]\n        \n        ax.bar(states, scores, color=colors)\n        ax.set_xlabel('State', fontsize=12)\n        ax.set_ylabel('Eigenvector Centrality Score', fontsize=12)\n        ax.set_title('Most Influential States in Interstate Commerce Network\\n(Top 3: TX, CA, NY)', fontsize=14)\n        ax.grid(True, alpha=0.3, axis='y')\n        \n        # Add text annotation\n        ax.text(0.02, 0.95, 'Red bars: Top 3 most influential states', \n                transform=ax.transAxes, fontsize=10, \n                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n        \n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n        \n        print(f\"\\n✓ Key Finding Confirmed: TX, CA, NY are the top 3 most influential states\")\n        print(f\"  in interstate commerce networks (eigenvector centrality)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract Bilateral Flows Between Top States\n",
    "\n",
    "Analyze the most significant commodity flows between the influential states identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract flows between the top 3 most influential states: TX, CA, NY\nif 'results' not in locals():\n    print(\"ERROR: Please run Step 5 first to load centrality results.\")\nelse:\n    # Focus on the top 3 most influential states from MESO level\n    meso_leaders = results['three_level_analysis']['meso_level']['leaders'][:3]\n    top_3_states = [leader[1] for leader in meso_leaders]  # TX, CA, NY\n    \n    states_list = ','.join(sorted(top_3_states))\n    print(f\"Analyzing specific commodity flows between top 3 influential states: {states_list}\")\n    \n    # Run flow extraction focusing only on TX, CA, NY\n    !python flow_extraction.py --data cfs_2017_puf.csv --states {states_list} --top-n 25"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Display Flow Analysis Results\n",
    "\n",
    "Show the most significant bilateral flows between influential states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display specific commodity flows between TX, CA, NY\nif not os.path.exists('results'):\n    print(\"ERROR: Results directory not found. Please run Step 6 first.\")\nelse:\n    flow_files = os.listdir('results')\n    csv_files = [f for f in flow_files if f.startswith('bilateral_flows') and f.endswith('.csv')]\n    \n    if not csv_files:\n        print(\"ERROR: No bilateral flow results found. Please run Step 6 first.\")\n    else:\n        csv_file = csv_files[0]\n        \n        flows_df = pd.read_csv(f'results/{csv_file}')\n        \n        # Display top flows with commodity details\n        print(\"=\" * 80)\n        print(\"TOP COMMODITY FLOWS BETWEEN MOST INFLUENTIAL STATES (TX, CA, NY)\")\n        print(\"=\" * 80)\n        print(\"\\nRank | Route        | Commodity | Value ($B) | Weight (M tons)\")\n        print(\"-\" * 80)\n        \n        for idx, row in flows_df.head(15).iterrows():\n            commodity = row['commodity_name'] if 'commodity_name' in row.index else f\"SCTG-{row['SCTG']}\"\n            print(f\"{idx+1:4d} | {row['orig_state_name']:^2} → {row['dest_state_name']:^2} | {commodity:^15} | \"\n                  f\"${row['weighted_value']/1e9:8.2f} | {row['weighted_tons']/1e6:8.2f}\")\n        \n        # Summary by route\n        print(\"\\n\" + \"=\" * 80)\n        print(\"SUMMARY BY ROUTE\")\n        print(\"=\" * 80)\n        route_summary = flows_df.groupby(['orig_state_name', 'dest_state_name']).agg({\n            'weighted_value': 'sum',\n            'weighted_tons': 'sum'\n        }).round(2)\n        \n        for (origin, dest), data in route_summary.iterrows():\n            print(f\"{origin} → {dest}: ${data['weighted_value']/1e9:.1f}B ({data['weighted_tons']/1e6:.1f}M tons)\")\n        \n        # Top commodities overall\n        print(\"\\n\" + \"=\" * 80)\n        print(\"TOP COMMODITIES IN TX-CA-NY TRIANGLE\")\n        print(\"=\" * 80)\n        commodity_summary = flows_df.groupby('SCTG').agg({\n            'weighted_value': 'sum',\n            'commodity_name': 'first'\n        }).sort_values('weighted_value', ascending=False).head(5)\n        \n        for sctg, data in commodity_summary.iterrows():\n            commodity = data['commodity_name'] if 'commodity_name' in data.index else f\"SCTG-{sctg}\"\n            print(f\"  {commodity}: ${data['weighted_value']/1e9:.1f}B\")\n        \n        print(f\"\\nTotal trade volume between TX, CA, NY: ${flows_df['weighted_value'].sum()/1e9:.1f} billion\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 8: Network Visualization\n\nGenerate a simple network diagram showing trade flows between the most influential states."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport numpy as np\n\n# Check if results are loaded\nif 'results' not in locals():\n    print(\"ERROR: Please run Step 5 first to load centrality results.\")\nelse:\n    # Check if flow data exists\n    if not os.path.exists('results'):\n        print(\"ERROR: Please run Step 6 first to generate flow data.\")\n    else:\n        flow_files = os.listdir('results')\n        csv_files = [f for f in flow_files if f.startswith('bilateral_flows') and f.endswith('.csv')]\n        \n        if not csv_files:\n            print(\"ERROR: No flow data found. Please run Step 6 first.\")\n        else:\n            # SCTG commodity mapping\n            SCTG_CODES = {\n                1: 'Animals and Fish (live)', 2: 'Cereal Grains', 3: 'Agricultural Products', \n                4: 'Animal Feed and Products', 5: 'Meat, Poultry, Fish, Seafood',\n                6: 'Milled Grain Products and Bakery', 7: 'Other Prepared Foodstuffs', \n                8: 'Alcoholic Beverages', 9: 'Tobacco Products',\n                10: 'Monumental or Building Stone', 11: 'Natural Sands', 12: 'Gravel and Crushed Stone',\n                13: 'Other Non-Metallic Minerals', 14: 'Metallic Ores and Concentrates',\n                15: 'Coal', 16: 'Crude Petroleum', 17: 'Gasoline and Aviation Fuel', \n                18: 'Fuel Oils', 19: 'Other Coal and Petroleum Products',\n                20: 'Basic Chemicals', 21: 'Pharmaceutical Products', 22: 'Fertilizers',\n                23: 'Other Chemical Products', 24: 'Plastics and Rubber',\n                25: 'Logs and Wood in the Rough', 26: 'Wood Products', 27: 'Pulp, Paper, Paperboard',\n                28: 'Paper or Paperboard Articles', 29: 'Printed Products', 30: 'Textiles and Leather',\n                31: 'Non-Metallic Mineral Products', 32: 'Base Metal in Primary Forms', \n                33: 'Articles of Base Metal', 34: 'Machinery',\n                35: 'Electronic and Electrical Equipment', 36: 'Motorized and Other Vehicles',\n                37: 'Transportation Equipment', 38: 'Precision Instruments',\n                39: 'Furniture and Lighting', 40: 'Miscellaneous Manufactured Products',\n                41: 'Waste and Scrap', 43: 'Mixed Freight'\n            }\n            \n            # Load flow data\n            csv_file = csv_files[0]\n            flows_df = pd.read_csv(f'results/{csv_file}')\n            \n            # Create network visualization\n            fig, ax = plt.subplots(figsize=(14, 10))\n            \n            # Define state positions (triangle layout)\n            positions = {\n                'TX': (0.15, 0.15),   # Bottom left\n                'CA': (0.85, 0.15),   # Bottom right  \n                'NY': (0.5, 0.85)     # Top center\n            }\n            \n            # Draw state nodes\n            for state, pos in positions.items():\n                circle = plt.Circle(pos, 0.06, color='darkgray', zorder=3)\n                ax.add_patch(circle)\n                ax.text(pos[0], pos[1], state, ha='center', va='center', \n                       fontsize=14, fontweight='bold', color='white', zorder=4)\n            \n            # Calculate flow values and top commodities for each route\n            route_data = {}\n            for (origin, dest), group in flows_df.groupby(['orig_state_name', 'dest_state_name']):\n                total_value = group['weighted_value'].sum()\n                # Find top commodity for this route\n                top_commodity = group.loc[group['weighted_value'].idxmax()]\n                sctg_code = top_commodity['SCTG']\n                commodity_name = SCTG_CODES.get(sctg_code, f\"SCTG-{sctg_code}\")\n                route_data[(origin, dest)] = {\n                    'value': total_value,\n                    'top_commodity': commodity_name,\n                    'sctg_code': sctg_code\n                }\n            \n            # Normalize arrow thickness\n            max_flow = max([data['value'] for data in route_data.values()])\n            \n            # Draw arrows for each flow with commodity labels\n            for (origin, dest), data in route_data.items():\n                if origin in positions and dest in positions:\n                    start_pos = positions[origin]\n                    end_pos = positions[dest]\n                    value = data['value']\n                    commodity = data['top_commodity']\n                    \n                    # Calculate arrow thickness\n                    thickness = (value / max_flow) * 0.008\n                    \n                    # Draw arrow with slight curve to avoid overlap\n                    curve_direction = 0.15 if (origin, dest) < (dest, origin) else -0.15\n                    arrow = patches.FancyArrowPatch(start_pos, end_pos,\n                                                   connectionstyle=f\"arc3,rad={curve_direction}\",\n                                                   arrowstyle='->', \n                                                   mutation_scale=15,\n                                                   linewidth=thickness * 1200,\n                                                   color='steelblue',\n                                                   alpha=0.7,\n                                                   zorder=2)\n                    ax.add_patch(arrow)\n                    \n                    # Add value and commodity label for all flows (lowered threshold for complete triangle)\n                    if value > max_flow * 0.05:  # Label flows >5% of max (shows all 6 routes)\n                        # Calculate label position along the curved path\n                        mid_x = (start_pos[0] + end_pos[0]) / 2\n                        mid_y = (start_pos[1] + end_pos[1]) / 2\n                        \n                        # Offset label based on curve direction\n                        label_offset_x = curve_direction * 0.08\n                        label_offset_y = 0.04 if curve_direction > 0 else -0.04\n                        \n                        # Shorten commodity name for arrow labels\n                        short_commodity = commodity[:15] + \"...\" if len(commodity) > 15 else commodity\n                        \n                        ax.text(mid_x + label_offset_x, mid_y + label_offset_y, \n                               f'${value/1e9:.1f}B\\n{short_commodity}', \n                               ha='center', va='center', fontsize=8,\n                               bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.9),\n                               zorder=5)\n            \n            # Create commodity legend with proper names\n            unique_commodities = {}\n            for data in route_data.values():\n                sctg = data['sctg_code']\n                commodity = data['top_commodity']\n                if sctg not in unique_commodities:\n                    unique_commodities[sctg] = commodity\n            \n            # Build legend text with proper commodity names\n            legend_text = \"Commodity Types:\\n\"\n            for sctg, commodity in sorted(unique_commodities.items()):\n                # Shorten commodity names for legend\n                short_name = commodity[:22] + \"...\" if len(commodity) > 22 else commodity\n                legend_text += f\"SCTG-{sctg}: {short_name}\\n\"\n            \n            # Set plot properties\n            ax.set_xlim(0, 1)\n            ax.set_ylim(0, 1)\n            ax.set_aspect('equal')\n            ax.axis('off')\n            ax.set_title('Interstate Commerce Network: TX-CA-NY Triangle\\nArrow thickness = Trade volume, Labels show top commodity per route', \n                        fontsize=14, pad=20)\n            \n            # Add usage legend (bottom left)\n            ax.text(0.02, 0.02, 'Arrow thickness = Trade volume\\nLabels: Value + Top commodity\\nAll 6 routes labeled', \n                   transform=ax.transAxes, fontsize=10,\n                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n            \n            # Add commodity legend (bottom right)\n            ax.text(0.98, 0.02, legend_text.strip(), \n                   transform=ax.transAxes, fontsize=9, ha='right', va='bottom',\n                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\", alpha=0.8))\n            \n            plt.tight_layout()\n            plt.show()\n            \n            print(\"Enhanced network visualization complete!\")\n            print(f\"Total trade flows visualized: ${sum([data['value'] for data in route_data.values()])/1e9:.1f} billion\")\n            \n            # Print route summary\n            print(\"\\nRoute Summary:\")\n            for (origin, dest), data in sorted(route_data.items(), key=lambda x: x[1]['value'], reverse=True):\n                print(f\"  {origin} → {dest}: ${data['value']/1e9:.1f}B (Top: {data['top_commodity']})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation Information\n",
    "\n",
    "**Data Source:**\n",
    "U.S. Census Bureau. (2017). Commodity Flow Survey Public Use File. \n",
    "Retrieved from https://www.census.gov/programs-surveys/cfs/data/datasets.html\n",
    "\n",
    "**Analysis Code:**\n",
    "Available at: https://github.com/rsthornton/cfs-network-analysis\n",
    "\n",
    "**Method:**\n",
    "Three-level network centrality analysis using NetworkX, with survey-weighted interstate commodity flows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}