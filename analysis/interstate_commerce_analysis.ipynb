{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interstate Commerce Network Analysis\n",
    "\n",
    "**Research Questions:**\n",
    "1. Which states are most influential in our network of interstate flows?\n",
    "2. What are the most significant flows between those states?\n",
    "\n",
    "**Data Source:** U.S. Census Bureau CFS 2017 Public Use File\n",
    "\n",
    "**Note:** This notebook downloads official Census data and uses validated analysis scripts to reproduce research findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Download CFS Data from Census Bureau\n",
    "\n",
    "Download the official CFS 2017 Public Use File directly from the U.S. Census Bureau (~140MB, takes 2-3 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download CFS 2017 data from Census Bureau\nimport os\nimport urllib.request\nimport zipfile\n\n# Census Bureau official data URL\ndata_url = \"https://www2.census.gov/programs-surveys/cfs/datasets/2017/CFS%202017%20PUF%20CSV.zip\"\n\n# Download if not already present\nif not os.path.exists('cfs_2017_puf.csv'):\n    print(\"Downloading CFS 2017 data from Census Bureau...\")\n    urllib.request.urlretrieve(data_url, 'cfs_data.zip')\n    \n    print(\"Extracting data...\")\n    with zipfile.ZipFile('cfs_data.zip', 'r') as zip_ref:\n        zip_ref.extractall('.')\n    \n    # Rename the extracted file to match what our scripts expect\n    if os.path.exists('CFS 2017 PUF CSV.csv'):\n        os.rename('CFS 2017 PUF CSV.csv', 'cfs_2017_puf.csv')\n        print(\"Renamed file to cfs_2017_puf.csv\")\n    \n    # Clean up zip file\n    os.remove('cfs_data.zip')\n    print(\"Data downloaded successfully!\")\nelse:\n    print(\"CFS data already present.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Analysis Scripts from GitHub\n",
    "\n",
    "Download our validated analysis scripts from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download analysis scripts from GitHub\n",
    "import urllib.request\n",
    "\n",
    "# GitHub raw file URLs\n",
    "base_url = \"https://raw.githubusercontent.com/rsthornton/cfs-network-analysis/main/analysis/\"\n",
    "\n",
    "scripts = [\n",
    "    \"centrality_analysis.py\",\n",
    "    \"flow_extraction.py\"\n",
    "]\n",
    "\n",
    "for script in scripts:\n",
    "    if not os.path.exists(script):\n",
    "        print(f\"Downloading {script}...\")\n",
    "        urllib.request.urlretrieve(base_url + script, script)\n",
    "        print(f\"  ✓ {script} downloaded\")\n",
    "    else:\n",
    "        print(f\"  ✓ {script} already present\")\n",
    "\n",
    "print(\"\\nAnalysis scripts ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install Required Libraries\n",
    "\n",
    "Install the necessary Python packages for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas networkx matplotlib seaborn -q\n",
    "\n",
    "print(\"Required libraries installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Three-Level Centrality Analysis\n",
    "\n",
    "Identify the most influential states using our three-level framework:\n",
    "- **MACRO**: Regional bridging power (betweenness centrality)\n",
    "- **MESO**: Influence networks (eigenvector centrality)\n",
    "- **MICRO**: Distribution power (weighted out-degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run centrality analysis\n!python centrality_analysis.py --data cfs_2017_puf.csv --top-n 10\n\nprint(\"\\nCentrality analysis complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load and Display Centrality Results\n",
    "\n",
    "Load the results and create a simple summary table showing the most influential states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport json\nimport matplotlib.pyplot as plt\n\n# Check if results directory exists\nif not os.path.exists('results'):\n    print(\"ERROR: Results directory not found. Please run Step 4 first.\")\nelse:\n    # Load centrality results\n    results_files = os.listdir('results')\n    json_files = [f for f in results_files if f.startswith('centrality_analysis') and f.endswith('.json')]\n    \n    if not json_files:\n        print(\"ERROR: No centrality analysis results found. Please run Step 4 first.\")\n    else:\n        json_file = json_files[0]\n        \n        with open(f'results/{json_file}', 'r') as f:\n            results = json.load(f)\n        \n        # Create summary table of top 5 states at each level\n        print(\"=\" * 60)\n        print(\"MOST INFLUENTIAL STATES BY LEVEL (Top 5)\")\n        print(\"=\" * 60)\n        \n        levels = [\n            ('MACRO - Regional Bridging', 'macro_level'),\n            ('MESO - Influence Networks', 'meso_level'),\n            ('MICRO - Distribution Power', 'micro_level')\n        ]\n        \n        for level_name, level_key in levels:\n            print(f\"\\n{level_name}:\")\n            leaders = results['three_level_analysis'][level_key]['leaders'][:5]\n            for i, state_data in enumerate(leaders, 1):\n                # state_data is a list: [state_id, state_code, score]\n                state_code = state_data[1]\n                score = state_data[2]\n                print(f\"  {i}. {state_code}: {score:.3f}\")\n        \n        # Show multi-level leaders\n        print(\"\\n\" + \"=\" * 60)\n        print(\"MULTI-LEVEL LEADERS (States appearing in multiple rankings)\")\n        print(\"=\" * 60)\n        for state in results['three_level_analysis']['multi_level_leaders'][:5]:\n            print(f\"  {state['state_name']}: {state['level_count']} levels - Score: {state['total_score']:.2f}\")\n        \n        # Create visualization showing key finding: TX, CA, NY as top 3 influential states\n        print(\"\\n\" + \"=\" * 60)\n        print(\"KEY FINDING: Most Influential States in Network\")\n        print(\"=\" * 60)\n        \n        fig, ax = plt.subplots(figsize=(10, 6))\n        \n        # Show MESO level (Influence Networks) - the key research finding\n        meso_leaders = results['three_level_analysis']['meso_level']['leaders'][:10]\n        states = [leader[1] for leader in meso_leaders]\n        scores = [leader[2] for leader in meso_leaders]\n        \n        # Highlight top 3 (TX, CA, NY) in different colors\n        colors = ['#d73027' if i < 3 else 'steelblue' for i in range(len(states))]\n        \n        ax.bar(states, scores, color=colors)\n        ax.set_xlabel('State', fontsize=12)\n        ax.set_ylabel('Eigenvector Centrality Score', fontsize=12)\n        ax.set_title('Most Influential States in Interstate Commerce Network\\n(Top 3: TX, CA, NY)', fontsize=14)\n        ax.grid(True, alpha=0.3, axis='y')\n        \n        # Add text annotation\n        ax.text(0.02, 0.95, 'Red bars: Top 3 most influential states', \n                transform=ax.transAxes, fontsize=10, \n                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n        \n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()\n        \n        print(f\"\\n✓ Key Finding Confirmed: TX, CA, NY are the top 3 most influential states\")\n        print(f\"  in interstate commerce networks (eigenvector centrality)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract Bilateral Flows Between Top States\n",
    "\n",
    "Analyze the most significant commodity flows between the influential states identified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get top states from centrality analysis\nif 'results' not in locals():\n    print(\"ERROR: Please run Step 5 first to load centrality results.\")\nelse:\n    top_states = set()\n    for level in ['macro_level', 'meso_level', 'micro_level']:\n        leaders = results['three_level_analysis'][level]['leaders'][:5]\n        for state_data in leaders:\n            # state_data is a list: [state_id, state_code, score]\n            state_code = state_data[1]\n            top_states.add(state_code)\n    \n    states_list = ','.join(sorted(top_states))\n    print(f\"Analyzing flows between: {states_list}\")\n    \n    # Run flow extraction for top states\n    !python flow_extraction.py --data cfs_2017_puf.csv --states {states_list} --top-n 20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Display Flow Analysis Results\n",
    "\n",
    "Show the most significant bilateral flows between influential states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load flow results\nif not os.path.exists('results'):\n    print(\"ERROR: Results directory not found. Please run Step 6 first.\")\nelse:\n    flow_files = os.listdir('results')\n    csv_files = [f for f in flow_files if f.startswith('bilateral_flows') and f.endswith('.csv')]\n    \n    if not csv_files:\n        print(\"ERROR: No bilateral flow results found. Please run Step 6 first.\")\n    else:\n        csv_file = csv_files[0]\n        \n        flows_df = pd.read_csv(f'results/{csv_file}')\n        \n        # Display top flows\n        print(\"=\" * 60)\n        print(\"TOP 10 BILATERAL FLOWS BETWEEN INFLUENTIAL STATES\")\n        print(\"=\" * 60)\n        print(\"\\nRank | Origin → Destination | Value ($B) | Weight (M tons)\")\n        print(\"-\" * 60)\n        \n        for idx, row in flows_df.head(10).iterrows():\n            print(f\"{idx+1:4d} | {row['orig_state_name']:^6} → {row['dest_state_name']:^6} | \"\n                  f\"${row['weighted_value']/1e9:8.2f} | {row['weighted_tons']/1e6:8.2f}\")\n        \n        # Summary statistics\n        print(\"\\n\" + \"=\" * 60)\n        print(\"SUMMARY STATISTICS\")\n        print(\"=\" * 60)\n        print(f\"Total flow value analyzed: ${flows_df['weighted_value'].sum()/1e9:.1f} billion\")\n        print(f\"Number of state pairs: {len(flows_df)}\")\n        print(f\"Average flow value: ${flows_df['weighted_value'].mean()/1e9:.2f} billion\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 8: Multi-Level Summary Visualization\n\nGenerate a summary chart showing states that excel across multiple centrality measures."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\n# Check if results are loaded\nif 'results' not in locals():\n    print(\"ERROR: Please run Step 5 first to load centrality results.\")\nelse:\n    # Create summary chart showing multi-level performance\n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    leaders = results['three_level_analysis']['multi_level_leaders'][:10]\n    states = [l['state_name'] for l in leaders]\n    scores = [l['total_score'] for l in leaders]\n    \n    ax.bar(states, scores, color='steelblue')\n    ax.set_xlabel('State', fontsize=12)\n    ax.set_ylabel('Multi-Level Performance Score', fontsize=12)\n    ax.set_title('States Excelling Across Multiple Centrality Measures\\n(Combines Regional Bridging + Network Influence + Distribution Power)', fontsize=13)\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Analysis complete! Key findings:\")\n    print(f\"1. TX, CA, NY identified as most influential states (network influence)\")\n    print(f\"2. CA, TX show strongest multi-level performance (combined measures)\")\n    print(f\"3. Bilateral flows quantified between top states\")\n    print(f\"4. Results ready for academic citation\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation Information\n",
    "\n",
    "**Data Source:**\n",
    "U.S. Census Bureau. (2017). Commodity Flow Survey Public Use File. \n",
    "Retrieved from https://www.census.gov/programs-surveys/cfs/data/datasets.html\n",
    "\n",
    "**Analysis Code:**\n",
    "Available at: https://github.com/rsthornton/cfs-network-analysis\n",
    "\n",
    "**Method:**\n",
    "Three-level network centrality analysis using NetworkX, with survey-weighted interstate commodity flows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}